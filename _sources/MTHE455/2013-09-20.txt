*******************************
Another Graph with Conditioning
*******************************

Last Time:

.. image:: .static/09.21.1.jpg
    :width: 50%

.. math::
    P(connected) = \frac{k}{k+r}

Now consider a graph with :math:`n` nodes.

Each node, independently, chooses a node at random (equally likely, including itself), and draws an arc between itself and that node.

What is the probability that this graph is connected?

Fix a node, call it node 1.

Follow its choice arc, and keep following the path of choice arcs until you reach the same node twice.

.. image:: .static/09.21.2.jpg
    :width: 50%

Let :math:`N` denote the number of nodes obtained in the path. Possible values of :math:`N` are :math:`1,2,3,...,n`.

Condition on :math:`N` to find :math:`P(connected)`.

Given :math:`N=k`:

if :math:`k \neq n`, the graph is connected if one of the "other" :math:`n-k` nodes does not choose a node in the subgraph we constructed by following the choices of each node in that subgraph.

This is the same mechanism as the previous example. (weight :math:`k` for node 0, and :math:`r=n-k`.)

Therefore,

.. math::
    P(connected|N=k) = \frac{k}{k+n-k} = \frac{k}{n}

So,

.. math::
    P(connected) = \frac{1}{n}\sum\limits_{k=1}^n kP(N=k)

    = \frac{E[N]}{n}

and

.. math::
    E[N] = P(N=1)+

    P(N=2) + P(N=2) +

    ...

    P(N=n)+...+P(N=n)

    =P(N \geq 1)+P(N \geq 2)+...+P(N \geq n)

    = \sum\limits_{i=1}^n P(N \geq i)

Now,

.. math::
    P(N \geq i) = P(\text{first }i-1\text{ nodes choose previously unchosen nodes})

    =(\frac{n-1}{n})(\frac{n-2}{n})...(\frac{n-(i-1)}{n})

    = \frac{1}{n^{i-1}}\frac{(n-1)!}{(n-i)!}

So,

.. math::
    P(connected) = (n-1)! \sum\limits^n_{i=1}\frac{1}{(n-i)!n^i}

Substituting :math:`j=n-i`,

.. math::
    = (n-1)! \sum\limits^n_{i=1}\frac{1}{j!n^{n-j}}

    = \frac{(n-1)!}{n^n}\sum_{j=0}^{n-1}

Some approximations
===================

(1) if :math:`X~Poisson(\lambda_i)`, :math:`i=1,...,n` and :math:`X_1, ... X_n` are independent, then :math:`X_1+...+X_n~Poisson(\lambda_1+...+\lambda_n)`

In particular, if :math:`X~Poisson(n)`, then :math:`X` has the same distribution as :math:`X_1+...+X_n` where :math:`X_i~Poisson(1)` are i.i.d.

(2) Central limit theorem

if :math:`X_1,X_2,...` are i.i.d. with mean :math:`\mu`, variance :math:`\sigma^2<\infty`, then,

.. math::
    \frac{\sum_{i=1}^n X_i - n\mu}{\sqrt n \sigma} \to N(0,1) \text{ as }n\to\infty

First note that if :math:`X~Poisson(n)`, then 

.. math::
    P(X<n)=\sum_{i=0}^{n-1} \frac{n^i}{i!}e^{-n}

Moreover, since :math:`X~X_1+X_2+...+X_n` where the :math:`X_i~Poisson(1)` i.i.d. by the central limit. Then, this is approximately normal since the mean of the distribution of :math:`X` is :math:`n` approximately :math:`\frac{1}{2} \approx P(X<n)`

i.e.

.. math::
    \sum_{i=0}^{n-1} \frac{n^i}{i!}e^{-n} \approx \frac{1}{2}

or, in the form we want,

.. math::
    \sum_{i=0}^{n-1} \frac{n^i}{i!} \approx \frac{e^n}{2}

One more:

(3) Stirling's approximation

Let :math:`X ~Poisson(n)`.

Then 

.. math::
    P(X=n)=\frac{n^n}{n!}e^{-n}

    =P(n-1<X\leq n)

    =P(\frac{n-1-n}{\sqrt n} < \frac{X-n}{\sqrt n} \leq \frac{n-n}{\sqrt n})

    \approx P(-\frac{1}{\sqrt n}<Z\leq 0)

where :math:`Z~N(0,1)`

.. math::
    =\int\limits_{-\frac{1}{\sqrt{n}}}^0 \frac{1}{\sqrt{2\pi}}e^{\frac{-t^2}{2}} dt

for :math:`n` big, 

.. math::
    \approx \frac{1}{\sqrt n} \frac{1}{\sqrt{2\pi}}

So, 

.. math::
    n! \approx \sqrt{2\pi}n^{n+\frac{1}{2}}e^{-n}

and :math:`(n-1)! \approx \sqrt{2\pi}(n-1)^{n-\frac{1}{2}}e^{-(n-1)}`

So,

.. math::
    P(connected) \approx \frac{\sqrt{2\pi}(n-1)^{n-\frac{1}{2}}e^{-(n-1)}e^n}{n^n * 2}

    = \sqrt{\frac{\pi}{2}}(\frac{n-1}{n}^n)\sqrt{\frac{1}{\sqrt{n-1}}}e

    (1-\frac{1}{n})^n \approx e^-1

    \approx \sqrt{\frac{\pi}{2(n-1)}}
