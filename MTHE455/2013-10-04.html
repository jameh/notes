
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Introduction to Stationary Distributions &mdash; Jamie&#39;s reStructured Notes 0.1 documentation</title>
    
    <link rel="stylesheet" href="../_static/flasky.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="Jamie&#39;s reStructured Notes 0.1 documentation" href="../index.html" />
    <link rel="up" title="MTHE 455 - Stochastic Processes &amp; Applications" href="index.html" />
    <link rel="next" title="Existence and Uniqueness of Stationary Distributions" href="2013-10-07.html" />
    <link rel="prev" title="Generating Function Example" href="2013-10-02.html" />
   
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9">

  </head>
  <body>
  
  

    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="2013-10-07.html" title="Existence and Uniqueness of Stationary Distributions"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="2013-10-02.html" title="Generating Function Example"
             accesskey="P">previous</a> |</li>
        <li><a href="../index.html">Jamie&#39;s reStructured Notes 0.1 documentation</a> &raquo;</li>
          <li><a href="index.html" accesskey="U">MTHE 455 - Stochastic Processes &amp; Applications</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="introduction-to-stationary-distributions">
<h1>Introduction to Stationary Distributions<a class="headerlink" href="#introduction-to-stationary-distributions" title="Permalink to this headline">¶</a></h1>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">these notes were taken practically verbatim from Section 13 of <a class="reference external" href="http://www.mast.queensu.ca/~stat455/lecturenotes/set3.pdf">Prof. Takahara&#8217;s online notes</a></p>
</div>
<p>We briefly review the classification of states in a Markov chain with a quick example and then begin the discussion of the important notion of <em>stationary distributions</em>.</p>
<p>First, let&#8217;s review a little bit with the following:</p>
<div class="admonition-example admonition">
<p class="first admonition-title">Example</p>
<p>Suppose we have the following transition matrix:</p>
<div class="math">
\[\begin{split}P=\begin{array}{l|ccccccccccc}
   &amp; 1 &amp;  2 &amp;  3 &amp;  4 &amp;  5 &amp;  6 &amp;  7 &amp;  8 &amp;  9 &amp; 10 \\
\hline
1  &amp;   &amp;    &amp;    &amp;    &amp;    &amp;    &amp; 1  &amp;    &amp;    &amp;    \\
2  &amp;   &amp; .3 &amp; .3 &amp; .1 &amp; .3 &amp;    &amp;    &amp;    &amp;    &amp;    \\
3  &amp;   &amp;    &amp; .6 &amp;    &amp;    &amp;    &amp;    &amp; .4 &amp;    &amp;    \\
4  &amp;   &amp;    &amp;    &amp;  1 &amp;    &amp;    &amp;    &amp;    &amp;    &amp;    \\
5  &amp;   &amp; .4 &amp;    &amp;    &amp;    &amp; .3 &amp;    &amp; .3 &amp;    &amp;    \\
6  &amp;   &amp;    &amp;    &amp; .9 &amp;    &amp;    &amp; .1 &amp;    &amp;    &amp;    \\
7  &amp;   &amp;    &amp;    &amp;    &amp;    &amp;    &amp;    &amp;    &amp;    &amp;  1 \\
8  &amp;   &amp; .8 &amp;    &amp;    &amp;    &amp;    &amp;    &amp; .2 &amp;    &amp;    \\
9  &amp;   &amp;    &amp;    &amp;    &amp;    &amp;    &amp;    &amp;    &amp;  1 &amp;    \\
10 &amp; 1 &amp;    &amp;    &amp;    &amp;    &amp;    &amp;    &amp;    &amp;    &amp;
\end{array}\end{split}\]</div>
<p>Determine the equivalence classes, the period of each equivalence class, and whether each equivalence class is transient or recurrent.</p>
<p>Sometimes a useful technique for determining the equivalence classes in a Markov chain is to draw what is called a <em>state transition diagram</em>, which is a graph with one node for each state and with a (directed) edge between nodes <span class="math">\(i\)</span> and <span class="math">\(j\)</span> if <span class="math">\(p_{ij}&gt;0\)</span>. We also usually write the transition probability <span class="math">\(p_{ij}\)</span> beside the directed edge between nodes <span class="math">\(i\)</span> and <span class="math">\(j\)</span> if <span class="math">\(p_{ij}&gt;0\)</span></p>
<img alt="../_images/10.04.1.png" src="../_images/10.04.1.png" />
<p>Since the diagram displays all one-step transitions pictorially, it is usually easier to see the equivalence classes with the diagram than just by looking at the transition matrix. It helps if the diagram can be drawn neatly, with, for example, no edges crossing each other.</p>
<p>Usually when we construct a Markoc model for some system, the equivalence classes, if there are more than one, are apparent or obvious because we <em>designed</em> the model so that certain states go together and we designed them to be transient or recurrent.</p>
<p>Other times we may be trying to verify, modify, improve, or just understand someone else&#8217;s (complicated) model and one of the first things we may want to know is how to classify the states, and it may not be obvious or even easy to determine the equivalence classes if the state space is large and there are many transitions that don&#8217;t follow a regular pattern. For <span class="math">\(S\)</span> finite, the following algorithm determines <span class="math">\(T(i)\)</span>, the set of states accessible from <span class="math">\(i\)</span>, <span class="math">\(F(i)\)</span>, the set of states from which <span class="math">\(i\)</span> is accessible, and <span class="math">\(C(i)=F(i)\cap T(i)\)</span>, the equivalence class of state <span class="math">\(i\)</span>:</p>
<ol class="arabic simple">
<li>For each state <span class="math">\(i\in S\)</span>, let <span class="math">\(T(i)=\{i\}\)</span> and <span class="math">\(F(i)=\{\}\)</span>, the empty set.</li>
<li>For each state <span class="math">\(i\in S\)</span>, do the following: For each state <span class="math">\(k\in T(i)\)</span>, add to <span class="math">\(T(i)\)</span> all states <span class="math">\(j\)</span> such that <span class="math">\(p_{kj}&gt;0\)</span> (if <span class="math">\(k\)</span> is not already in <span class="math">\(T(i)\)</span>). Repeat this step until no further addition is possible.</li>
<li>For each state <span class="math">\(i\in S\)</span>, do the following: For each state <span class="math">\(j\in S\)</span>, add state <span class="math">\(j\)</span> to <span class="math">\(F(i)\)</span> if state <span class="math">\(i\)</span> is in <span class="math">\(T(j)\)</span>.</li>
<li>For each state <span class="math">\(i\in S\)</span>, let <span class="math">\(C(i)=F(i)\cap T(i)\)</span>.</li>
</ol>
<p class="last">Note that if <span class="math">\(C(i)=T(i)\)</span> (the equivalence class containing <span class="math">\(i\)</span> equals the set of states that are accessible from <span class="math">\(i\)</span>), then <span class="math">\(C(i)\)</span> is <em>closed</em> (hence recurrent since we are assuming <span class="math">\(S\)</span> is finite for this algorithm). This algorithm is taken from <em>An Introduction to Stochastic Processes</em>, by Edward P. C. Kao, Duxbury Press, 1997. Also in this reference is the listing of a <tt class="docutils literal"><span class="pre">MATLAB</span></tt> implementation of this algorithm.</p>
</div>
<div class="section" id="stationary-markov-chains">
<h2>Stationary Markov Chains<a class="headerlink" href="#stationary-markov-chains" title="Permalink to this headline">¶</a></h2>
<p>Now that we know the general architecture of a Markov chain, it&#8217;s time to look at how we might analyze a Markov chain to make predictions about system behaviour. For this we&#8217;ll first consider the concept of a <em>stationary distribution</em>. This is distinct from the notion of limiting probabilities, which we&#8217;ll consider a bit later. First, let&#8217;s define what we mean when we say that a process is <em>stationary</em>.</p>
<div class="admonition-definition admonition">
<p class="first admonition-title">Definition</p>
<p class="last">A (discrete-time) stochastic process <span class="math">\(\{X_n: n\geq 0\}\)</span> is <em>stationary</em> if for any time points <span class="math">\(i_1,...,i_n\)</span> and any <span class="math">\(m\geq 0\)</span>, the joint distribution of <span class="math">\((X_{i_1},...,X_{i_n})\)</span> is the same as the joint distribution of <span class="math">\((X_{i_1+m},...,X_{i_n+m})\)</span>.</p>
</div>
<p>So &#8220;stationary&#8221; refers to &#8220;stationary in time&#8221;. In particular, for a stationary process, the distribution of <span class="math">\(X_n\)</span> is the same for all <span class="math">\(n\)</span>.</p>
<p>So why do we care if our Markov chain is stationary? Well, if it were stationary <em>and</em> we knew what the distribution of each <span class="math">\(X_n\)</span> was then we would know a lot because we would know the long run proportion of time that the Markov chain was in any state. For example, suppose that the process was stationary and we knew that <span class="math">\(P(X_n=2)=\frac{1}{10}\)</span> for every <span class="math">\(n\)</span>. Then over 1000 time periods we should expect that roughly 100 of those time periods was spent in state 2, and over <span class="math">\(N\)</span> time periods roughly <span class="math">\(\frac{N}{10}\)</span> of those time periods was spent in state 2. As <span class="math">\(N\)</span> went to infinity, the <em>proportion</em> of time spent in state 2 will converge to <span class="math">\(\frac{1}{10}\)</span> (this can be proved rigorously bby some form of the Strong Law of Large Numbers). One of the attractive features of Markov chains is that we can often make them stationary <em>and</em> there is a nice and neat chacterization of the distribution of <span class="math">\(X_n\)</span> when it is stationary. We discuss this next.</p>
</div>
<div class="section" id="stationary-distributions">
<h2>Stationary Distributions<a class="headerlink" href="#stationary-distributions" title="Permalink to this headline">¶</a></h2>
<p>So how do we make a Markov chain stationary? If it can be made stationary (and not all of them can; for example, the simple random walk cannot be made stationary and, more generally, a Markov chain where all states were transient or null recurrent cannot be made stationary), then making it stationary is simply a matter of choosing the right initial distribution for <span class="math">\(X_0\)</span>. If the Markov chain is stationary, then we call the common distribution of all the <span class="math">\(X_n\)</span> the <em>stationary distribution</em> of the Markov chain.</p>
<p>here&#8217;s how we find a stationary distribution for a Markov chain.</p>
<div class="admonition-proposition admonition">
<p class="first admonition-title">Proposition</p>
<p>Suppose <span class="math">\(X\)</span> is a Markov chain with state space <span class="math">\(S\)</span> and transition probability matrix <span class="math">\(P\)</span>. If <span class="math">\(Π=(Π_j,j\in S)\)</span> is a distribution over <span class="math">\(S\)</span> (that is, <span class="math">\(Π\)</span> is a (row) vector with <span class="math">\(|S|\)</span> components such that <span class="math">\(\sum_jΠ_j=1\)</span> and <span class="math">\(Π_j\geq 0\)</span> for all <span class="math">\(j\in S\)</span>), then setting the initial distribution of <span class="math">\(X_0\)</span> equal to <span class="math">\(Π\)</span> will make the Markov chain stationary with stationary distribution <span class="math">\(Π\)</span> if</p>
<div class="math">
\[Π=ΠP\]</div>
<p>That is,</p>
<div class="math">
\[Π_j=\sum_{i\in S}Π_ip_{ij}\]</div>
<p>for all <span class="math">\(j\in S\)</span>.</p>
<p>In words, <span class="math">\(Π_j\)</span> is the dot product between <span class="math">\(Π\)</span> and the jth <em>column</em> of <span class="math">\(P\)</span>.</p>
<p>Proof:</p>
<p>Suppose <span class="math">\(Π\)</span> satisfies the above equations and we set the distribution of <span class="math">\(X_0\)</span> to be <span class="math">\(Π\)</span>. Let&#8217;s set <span class="math">\(μ(n)\)</span> to be the distribution of <span class="math">\(X_n\)</span> (that is, <span class="math">\(μ_j(n)=P(X_n=j)\)</span>). Then</p>
<div class="math">
\[\begin{split}μ_j(n)=P(X_n=j)&amp;=\sum_{i\in S}P(X_n=j|X_0=i)P(X_0=i)\\
               &amp;=\sum_{i\in S}p_{ij}(n)Π_i\end{split}\]</div>
<p>or, in matrix notation,</p>
<div class="math">
\[μ(n) = ΠP(n)\]</div>
<p>But, by the Chapman-Kolmogorov equations, we get</p>
<div class="math">
\[\begin{split}μ(n) &amp;= ΠP^n\\
     &amp;= (ΠP)P^{n-1}\\
     &amp;= ΠP^{n-1}\\
     &amp;...
     &amp;= ΠP\\
     &amp;= Π\end{split}\]</div>
<p class="last">We&#8217;ll stop the proof here.</p>
</div>
<p>Note we haven&#8217;t fully shown that the Markov chain <span class="math">\(X\)</span> is stationary with this choice of initial distribution <span class="math">\(Π\)</span> (though it is and not too difficult to show). But we have shown that by setting the distribution of <span class="math">\(X_0\)</span> to be <span class="math">\(Π\)</span>, the distribution of <span class="math">\(X_n\)</span> is also <span class="math">\(Π\)</span> for all <span class="math">\(n\geq 0\)</span>, and this is enough to say that <span class="math">\(Π_j\)</span> can be interpreted as the long run proportion of time the Markov chain spends in state <span class="math">\(j\)</span> (if such a <span class="math">\(Π\)</span> exists). We also haven&#8217;t answered any questions about the existence or uniqueness of a stationary distribution. But let&#8217;s finish off today with some examples.</p>
<div class="admonition-example admonition">
<p class="first admonition-title">Example</p>
<p>Consider just the recurrent class <span class="math">\(\{1,7,10\}\)</span> in our first example today. The transition matrix for this class is:</p>
<div class="math">
\[\begin{split}P=\begin{array}{l|ccc}
  &amp; 1 &amp; 7 &amp; 10\\
\hline
1 &amp; 0 &amp; 1 &amp; 0 \\
7 &amp; 0 &amp; 0 &amp; 1 \\
10 &amp; 1 &amp; 0 &amp; 0
\end{array}\end{split}\]</div>
<p class="last">Intuitively, the chain spends one third of its time in state 1, one third of its time in state 7, and one third of its time in state 10. One can easily verify that the distribution <span class="math">\(Π=(\frac{1}{3},\frac{1}{3},\frac{1}{3})\)</span> satisfies <span class="math">\(Π=ΠP\)</span>, and so <span class="math">\((\frac{1}{3},\frac{1}{3},\frac{1}{3})\)</span> is a stationary distribution.</p>
</div>
<div class="admonition-remark admonition">
<p class="first admonition-title">Remark</p>
<p class="last">Note that in the above example, <span class="math">\(p_{ii}(n)=0\)</span> if <span class="math">\(n\)</span> is not a multiple of 3 and <span class="math">\(p_{ii}=1\)</span> if <span class="math">\(n\)</span> is a multiple of 3, for all <span class="math">\(i\)</span>. Thus, clearly <span class="math">\(\lim_{n\to\infty p_{ii}(n)\)</span> does not exist because these numbers keep jumping back and forth between 0 and 1. This illustrates that limiting probabilities are not exactly the same thing as stationary probabilities. We want them to be! Later we&#8217;ll give just the right conditions for these two quantities to be equal.</p>
</div>
<div class="admonition-example-ross-p-257-30 admonition">
<p class="first admonition-title">Example (Ross, p.257 #30)</p>
<p>Three out of every four trucks on the road are followed by a car, while only one out of every five cars is followed by a truck. What fraction of vehicles on the road are trucks?</p>
<p>Solution:</p>
<p>Image sitting on the side of the road watching vehicles go by. If a truck goes by, the next vehicle will be a car with probability <span class="math">\(\frac{3}{4}\)</span> and will be a truck wwith probability <span class="math">\(\frac{1}{4}\)</span>. If a car goes by, the next vehicle will be a car with probability <span class="math">\(\frac{4}{5}\)</span>, and will be a truck with probability <span class="math">\(\frac{1}{5}\)</span>. We may set this up as a Markov chain with two states; 0=truck and 1=car, and transition probability matrix</p>
<div class="math">
\[\begin{split}P=\begin{array}{l|cc}
  &amp; 0 &amp; 1 \\
\hline
0 &amp; \frac{1}{4} &amp; \frac{3}{4} \\
1 &amp; \frac{1}{5} &amp; \frac{4}{5}
\end{array}\end{split}\]</div>
<p>The equations <span class="math">\(Π=ΠP\)</span> are</p>
<div class="math">
\[\begin{split}Π_0=\frac{1}{4}Π_0+\frac{1}{5}Π_1\\
Π_1=\frac{3}{4}Π_0+\frac{4}{5}Π_1\end{split}\]</div>
<p class="last">Solving, we have from the first equation that <span class="math">\(\frac{3}{4}Π_0=\frac{1}{5}Π_1\)</span> or <span class="math">\(Π_0=\frac{4}{15}Π_1\)</span>. Plugging this into the constraint that <span class="math">\(Π_0+Π_1=1\)</span>, gives us that <span class="math">\(\frac{4}{15}Π_1+Π_1=1\)</span>, or <span class="math">\(Π_1=\frac{15}{19}\)</span>. Therefore, <span class="math">\(Π_0=\frac{4}{19}\)</span>. That is, as we sit by the side of the road, the long run proportion of vehicles that will be trucks is <span class="math">\(\frac{4}{19}\)</span></p>
</div>
<div class="admonition-remark admonition">
<p class="first admonition-title">Remark</p>
<p class="last">Note that we need the constraint that <span class="math">\(Π_0+Π_1=1\)</span> in order to determine a solution. In general, we need the constraint that <span class="math">\(\sum_{j\in S}Π_j=1\)</span> in order to determine a solution. This is because the system of equations <span class="math">\(Π=ΠP\)</span> has just in itself infinitely many solutions (if <span class="math">\(Π\)</span> is a solution then so is <span class="math">\(cΠ\)</span> for any constant <span class="math">\(c\)</span>). We need the normalization constraint basically to determine <span class="math">\(c\)</span> to make <span class="math">\(Π\)</span> a proper distribution over <span class="math">\(S\)</span>.</p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Introduction to Stationary Distributions</a><ul>
<li><a class="reference internal" href="#stationary-markov-chains">Stationary Markov Chains</a></li>
<li><a class="reference internal" href="#stationary-distributions">Stationary Distributions</a></li>
</ul>
</li>
</ul>
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Overview</a><ul>
  <li><a href="index.html">MTHE 455 - Stochastic Processes &amp; Applications</a><ul>
      <li>Previous: <a href="2013-10-02.html" title="previous chapter">Generating Function Example</a></li>
      <li>Next: <a href="2013-10-07.html" title="next chapter">Existence and Uniqueness of Stationary Distributions</a></li>
  </ul></li>
  </ul></li>
</ul>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="../_sources/MTHE455/2013-10-04.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
  <div class="footer">
    &copy; Copyright 2013, Jamie Macdonald.
    Created using <a href="http://sphinx.pocoo.org/">Sphinx</a>.
  </div>
  
  </body>
</html>